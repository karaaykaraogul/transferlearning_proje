# -*- coding: utf-8 -*-
"""Transfer_Learning.ipynb

Automatically generated by Colaboratory.

# Transfer öğrenimi ve ince ayar

Önceden eğitilmiş bir model, daha önce büyük bir veri kümesi üzerinde, tipik olarak büyük ölçekli bir görüntü sınıflandırma görevinde eğitilmiş kaydedilmiş bir ağdır. Ya önceden eğitilmiş modeli olduğu gibi kullanırsınız ya da bu modeli belirli bir göreve göre özelleştirmek için aktarım öğrenmeyi kullanırsınız.


Özellik Çıkarma: Yeni örneklerden anlamlı özellikler çıkarmak için önceki bir ağ tarafından öğrenilen temsilleri kullanın. Önceden eğitilmiş modelin üzerine sıfırdan eğitilecek yeni bir sınıflandırıcı eklemeniz yeterlidir, böylece daha önce veri kümesi için öğrenilen özellik haritalarını yeniden düzenleyebilirsiniz.

Tüm modeli (yeniden) eğitmenize gerek yoktur. Temel evrişimli ağ, resimleri sınıflandırmak için jenerik olarak yararlı olan özellikleri zaten içermektedir. Bununla birlikte, önceden eğitilmiş modelin son sınıflandırma kısmı, orijinal sınıflandırma görevine özgüdür ve daha sonra modelin eğitildiği sınıflar kümesine özgüdür.

İnce Ayar: Dondurulmuş bir model tabanının üst katmanlarından birkaçını çözün ve hem yeni eklenen sınıflandırıcı katmanlarını hem de temel modelin son katmanlarını birlikte eğitin. Bu, belirli bir görevle daha alakalı hale getirmek için temel modeldeki üst düzey özellik temsillerine "ince ayar yapmamıza" olanak tanır.
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf

from tensorflow.keras.preprocessing import image_dataset_from_directory

"""## Veri ön işleme

### Veri indirme
"""

_URL = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip'
_VALIDATIONURL = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip'
path_to_zip = tf.keras.utils.get_file('horse-or-human.zip', origin=_URL, extract=True)
path_to_validation = tf.keras.utils.get_file('validation-horse-or-human.zip', origin=_VALIDATIONURL, extract=True)
PATH = os.path.dirname(path_to_zip)
VALIDATION_PATH = os.path.dirname(path_to_validation)

train_dir = PATH
validation_dir = VALIDATION_PATH



BATCH_SIZE = 32
IMG_SIZE = (300, 300)

train_dataset = image_dataset_from_directory(train_dir,
                                             shuffle=True,
                                             batch_size=BATCH_SIZE,
                                             image_size=IMG_SIZE)

validation_dataset = image_dataset_from_directory(validation_dir,
                                                  shuffle=True,
                                                  batch_size=BATCH_SIZE,
                                                  image_size=IMG_SIZE)

class_names = train_dataset.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""Validation data set'indeki verilerin %20'si test olarak kullanılmak için ayarlanıyor."""

val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)

print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))
print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))

"""### Veri kümesini performans için yapılandır

"""

AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)

"""### Veri büyütmeyi kullan

Büyük bir görüntü veri kümeniz olmadığında, rotasyon ve yatay çevirme gibi eğitim görüntülerine rastgele ancak gerçekçi dönüşümler uygulayarak örnek çeşitliliğini yapay olarak tanıtmak iyi bir uygulamadır.
"""

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),
])

for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')

"""### Piksel değerlerini yeniden ölçeklendir

Temel model olarak kullanılmak üzere `tf.keras.applications.MobileNetV2. Bu model, piksel değerlerini [-1,1] beklemektedir, ancak bu noktada görüntülerinizdeki piksel değerleri [0-255] . Yeniden ölçeklendirmek için modele dahil olan ön işleme yöntemini kullanın.
"""

preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input

""" Alternatif olarak, bir Yeniden Ölçeklendirme katmanı kullanarak piksel değerlerini [0,255] den [-1, 1] e yeniden ölçeklendirebilirsiniz."""

rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)

"""
Özellik çıkarma için MobileNet V2 katmanı seçilir. İlk olarak, ImageNet üzerinde eğitilmiş ağırlıklarla önceden yüklenmiş bir MobileNet V2 modelini somutlaştırın. İnclude_top = False bağımsız değişkenini belirterek, üst kısımdaki sınıflandırma katmanlarını içermeyen bir ağı yüklersiniz , bu özellik çıkarımı için idealdir"""

# Create the base model from the pre-trained model MobileNet V2
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')

image_batch, label_batch = next(iter(train_dataset))
feature_batch = base_model(image_batch)
print(feature_batch.shape)

"""##Özellik çıkarma

### Evrişimli tabanın dondurulması
"""

base_model.trainable = False

# Let's take a look at the base model architecture
base_model.summary()

"""### Bir sınıflandırma başlığı ekle

Özellikler bloğundan tahminler oluşturmak için, özellikleri görüntü başına tek bir 1280 öğeli vektöre dönüştürmek için bir tf.keras.layers.GlobalAveragePooling2D katmanını kullanarak uzamsal 5x5 uzamsal konumların ortalamasını alın.
"""

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
feature_batch_average = global_average_layer(feature_batch)
print(feature_batch_average.shape)

prediction_layer = tf.keras.layers.Dense(1)
prediction_batch = prediction_layer(feature_batch_average)
print(prediction_batch.shape)

"""Keras Functional API'yi kullanarak veri artırma, yeniden ölçeklendirme, temel model ve özellik çıkarıcı katmanlarını birbirine zincirleyerek bir model oluşturun. Daha önce belirtildiği gibi, modelimiz bir BatchNormalization katmanı içerdiğinden training = False kullanın."""

inputs = tf.keras.Input(shape=(300, 300, 3))
x = data_augmentation(inputs)
x = preprocess_input(x)
x = base_model(x, training=False)
x = global_average_layer(x)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = prediction_layer(x)
model = tf.keras.Model(inputs, outputs)

"""### Modeli derle

Modeli eğitmeden önce derle.
"""

base_learning_rate = 0.0001
model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

"""### Modeli eğit

10 dönem eğitimden sonra, doğrulama setinde ~%95 doğruluk görmelisiniz.
"""

initial_epochs = 10

loss0, accuracy0 = model.evaluate(validation_dataset)

print("initial loss: {:.2f}".format(loss0))
print("initial accuracy: {:.2f}".format(accuracy0))

history = model.fit(train_dataset,
                    epochs=initial_epochs,
                    validation_data=validation_dataset)

"""### Öğrenme eğrileri"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""## İnce ayar
Özellik çıkarma deneyinde, bir MobileNet V2 temel modelinin üzerinde yalnızca birkaç katmanı eğitiliyordu. Önceden eğitilmiş ağın ağırlıkları eğitim sırasında güncellenmedi.

Performansı daha da artırmanın bir yolu, eklenilen sınıflandırıcının eğitiminin yanı sıra önceden eğitilmiş modelin üst katmanlarının ağırlıklarını eğitmektir (veya "ince ayar" yapmaktır). Eğitim süreci, ağırlıkların genel özellik haritalarından veri setiyle özel olarak ilişkili özelliklere ayarlanmasını zorunlu kılacaktır.

### Modelin üst katmanlarını çözün
"""

base_model.trainable = True

# Let's take a look to see how many layers are in the base model
print("Number of layers in the base model: ", len(base_model.layers))

# Fine-tune from this layer onwards
fine_tune_at = 100

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable =  False

"""### Modeli derle

Çok daha büyük bir modeli eğitirken ve önceden eğitilmiş ağırlıkları yeniden ayarlamak istenildiğinde, bu aşamada daha düşük bir öğrenme oranı kullanmak önemlidir. Aksi takdirde, modelın derlenmesi uzun bir zaman alabilir.
"""

model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),
              metrics=['accuracy'])

model.summary()

len(model.trainable_variables)

"""### Modeli eğitmeye devam edin"""

fine_tune_epochs = 10
total_epochs =  initial_epochs + fine_tune_epochs

history_fine = model.fit(train_dataset,
                         epochs=total_epochs,
                         initial_epoch=history.epoch[-1],
                         validation_data=validation_dataset)

acc += history_fine.history['accuracy']
val_acc += history_fine.history['val_accuracy']

loss += history_fine.history['loss']
val_loss += history_fine.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.ylim([0.8, 1])
plt.plot([initial_epochs-1,initial_epochs-1],
          plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.ylim([0, 1.0])
plt.plot([initial_epochs-1,initial_epochs-1],
         plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""### Değerlendirme ve tahmin

Son olarak, test setini kullanarak modelin performansını yeni veriler üzerinde doğrulanabilir.
"""

loss, accuracy = model.evaluate(test_dataset)
print('Test accuracy :', accuracy)

#Retrieve a batch of images from the test set
image_batch, label_batch = test_dataset.as_numpy_iterator().next()
predictions = model.predict_on_batch(image_batch).flatten()

# Apply a sigmoid since our model returns logits
predictions = tf.nn.sigmoid(predictions)
predictions = tf.where(predictions < 0.5, 0, 1)


print('Predictions:\n', predictions.numpy())
print('Labels:\n', label_batch)


plt.figure(figsize=(15, 15))
for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(image_batch[i].astype("uint8"))
  plt.title(class_names[predictions[i]])
  plt.axis("off")